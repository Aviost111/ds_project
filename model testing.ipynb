{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Game Plan:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- linear regression, tree regression, random forest regression\n",
    "- we are checking each one with cross validation\n",
    "- we will check them with either mae or rmse (we'll read which is preferable)\n",
    "- we find which is the best based on the smallest error\n",
    "- and then we can do our feature selection (forward/backward) or forest tree selection for features\n",
    "- and then fine tuning of hyper parameter depending on which regression we use (grid search)\n",
    "- finally, we test our model :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from sklearn.dummy import DummyRegressor\n",
    "kf = KFold(n_splits=20, random_state=42, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Job Title', 'Salary Estimate', 'Job Description', 'Rating',\n",
       "       'Company Name', 'Location', 'Headquarters', 'Size', 'Founded',\n",
       "       'Type of ownership', 'Industry', 'Sector', 'Revenue', 'Competitors',\n",
       "       'Salary_Per_Hour', 'Min_Salary', 'Max_Salary', 'Avg Salary', 'State',\n",
       "       'Is_Headquarters', 'Age of Company', 'Python', 'Spark', 'AWS', 'Excel',\n",
       "       'Job Categories', 'Seniority', 'Description_Length', 'Competitor Count',\n",
       "       'Revenue_Adj'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('cleaned_glassdoor_dataset.csv',index_col=0)\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to know what this is\n",
    "df2 = pd.read_csv('no_outlier_cleaned_data.csv',index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001 to 5000 employees     150\n",
       "501 to 1000 employees      134\n",
       "10000+ employees           130\n",
       "201 to 500 employees       117\n",
       "51 to 200 employees         94\n",
       "5001 to 10000 employees     76\n",
       "1 to 50 employees           31\n",
       "Unknown                      9\n",
       "-1                           1\n",
       "Name: Size, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Size'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Is_Headquarters</th>\n",
       "      <th>Age of Company</th>\n",
       "      <th>Python</th>\n",
       "      <th>Spark</th>\n",
       "      <th>AWS</th>\n",
       "      <th>Excel</th>\n",
       "      <th>Description_Length</th>\n",
       "      <th>Competitor Count</th>\n",
       "      <th>Size_1 to 50 employees</th>\n",
       "      <th>...</th>\n",
       "      <th>Job Categories_Other</th>\n",
       "      <th>Job Categories_Other Engineer</th>\n",
       "      <th>Job Categories_Software Engineer</th>\n",
       "      <th>Seniority_Junior</th>\n",
       "      <th>Seniority_Senior</th>\n",
       "      <th>Seniority_none</th>\n",
       "      <th>Revenue_Adj_Unknown / Non-Applicable</th>\n",
       "      <th>Revenue_Adj_big</th>\n",
       "      <th>Revenue_Adj_medium</th>\n",
       "      <th>Revenue_Adj_small</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>3.2</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>208</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>3.6</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>753</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>3.1</td>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>698</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>4.2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>765</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>3.6</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>370</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>2.8</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>481</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>3.6</td>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>541</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>4.2</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>456</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>593 rows × 166 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rating  Is_Headquarters  Age of Company  Python  Spark  AWS  Excel  \\\n",
       "318     3.2                0              30       1      1    1      1   \n",
       "533     3.6                1              33       1      0    1      1   \n",
       "539     3.1                1             147       0      0    0      1   \n",
       "653     4.2                0              14       1      0    0      1   \n",
       "586     3.5                0              30       1      0    0      0   \n",
       "..      ...              ...             ...     ...    ...  ...    ...   \n",
       "857     3.5                0              25       1      1    0      0   \n",
       "79      3.6                1              95       1      0    0      1   \n",
       "759     2.8                1              50       0      0    0      0   \n",
       "730     3.6                0             171       0      1    1      1   \n",
       "117     4.2                1              87       1      0    0      1   \n",
       "\n",
       "     Description_Length  Competitor Count  Size_1 to 50 employees  ...  \\\n",
       "318                 208                 0                       1  ...   \n",
       "533                 753                 0                       0  ...   \n",
       "539                 698                 0                       0  ...   \n",
       "653                 765                 0                       0  ...   \n",
       "586                 158                 0                       0  ...   \n",
       "..                  ...               ...                     ...  ...   \n",
       "857                 151                 3                       0  ...   \n",
       "79                  370                 0                       0  ...   \n",
       "759                 481                 3                       0  ...   \n",
       "730                 541                 0                       0  ...   \n",
       "117                 456                 3                       0  ...   \n",
       "\n",
       "     Job Categories_Other  Job Categories_Other Engineer  \\\n",
       "318                     0                              0   \n",
       "533                     0                              0   \n",
       "539                     0                              0   \n",
       "653                     0                              0   \n",
       "586                     0                              0   \n",
       "..                    ...                            ...   \n",
       "857                     0                              0   \n",
       "79                      0                              0   \n",
       "759                     0                              0   \n",
       "730                     1                              0   \n",
       "117                     0                              0   \n",
       "\n",
       "     Job Categories_Software Engineer  Seniority_Junior  Seniority_Senior  \\\n",
       "318                                 0                 0                 1   \n",
       "533                                 0                 0                 0   \n",
       "539                                 0                 0                 1   \n",
       "653                                 0                 0                 0   \n",
       "586                                 0                 0                 0   \n",
       "..                                ...               ...               ...   \n",
       "857                                 0                 0                 0   \n",
       "79                                  0                 0                 0   \n",
       "759                                 0                 0                 0   \n",
       "730                                 0                 0                 0   \n",
       "117                                 0                 0                 1   \n",
       "\n",
       "     Seniority_none  Revenue_Adj_Unknown / Non-Applicable  Revenue_Adj_big  \\\n",
       "318               0                                     0                0   \n",
       "533               1                                     1                0   \n",
       "539               0                                     0                1   \n",
       "653               1                                     1                0   \n",
       "586               1                                     0                0   \n",
       "..              ...                                   ...              ...   \n",
       "857               1                                     1                0   \n",
       "79                1                                     0                1   \n",
       "759               1                                     0                0   \n",
       "730               1                                     0                1   \n",
       "117               0                                     1                0   \n",
       "\n",
       "     Revenue_Adj_medium  Revenue_Adj_small  \n",
       "318                   0                  1  \n",
       "533                   0                  0  \n",
       "539                   0                  0  \n",
       "653                   0                  0  \n",
       "586                   0                  1  \n",
       "..                  ...                ...  \n",
       "857                   0                  0  \n",
       "79                    0                  0  \n",
       "759                   1                  0  \n",
       "730                   0                  0  \n",
       "117                   0                  0  \n",
       "\n",
       "[593 rows x 166 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_n = pd.get_dummies(df.drop(['Job Title', 'Salary Estimate', 'Job Description',\n",
    "                               'Company Name','Location','Headquarters','Founded','Competitors',\n",
    "                               'Min_Salary','Max_Salary','Revenue'], axis=1))\n",
    "\n",
    "\n",
    "X = df_n.drop(['Avg Salary', 'Size_-1','Sector_-1','Industry_-1'], axis=1)\n",
    "y = df_n['Avg Salary'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=777)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Is_Headquarters</th>\n",
       "      <th>Age of Company</th>\n",
       "      <th>Python</th>\n",
       "      <th>Spark</th>\n",
       "      <th>AWS</th>\n",
       "      <th>Excel</th>\n",
       "      <th>Description_Length</th>\n",
       "      <th>Competitor Count</th>\n",
       "      <th>Size_1 to 50 employees</th>\n",
       "      <th>...</th>\n",
       "      <th>Job Categories_Other</th>\n",
       "      <th>Job Categories_Other Engineer</th>\n",
       "      <th>Job Categories_Software Engineer</th>\n",
       "      <th>Seniority_Junior</th>\n",
       "      <th>Seniority_Senior</th>\n",
       "      <th>Seniority_none</th>\n",
       "      <th>Revenue_Adj_Unknown / Non-Applicable</th>\n",
       "      <th>Revenue_Adj_big</th>\n",
       "      <th>Revenue_Adj_medium</th>\n",
       "      <th>Revenue_Adj_small</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>2.8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>777.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>4.4</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>345.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>3.3</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>3.3</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>3.2</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>575.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>569.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2.7</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>319.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>4.2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>668.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>3.9</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>420.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>3.9</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>734.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>581 rows × 165 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rating  Is_Headquarters  Age of Company  Python  Spark  AWS  Excel  \\\n",
       "325     2.8                1               8       1      0    0      1   \n",
       "674     4.4                1              38       1      0    0      0   \n",
       "396     3.3                1              14       0      0    0      0   \n",
       "895     3.3                1              34       0      0    0      1   \n",
       "859     3.2                1              64       1      0    0      1   \n",
       "..      ...              ...             ...     ...    ...  ...    ...   \n",
       "878     3.5                1              17       1      1    1      1   \n",
       "80      2.7                0              44       0      0    0      1   \n",
       "782     4.2                1              11       1      0    0      1   \n",
       "745     3.9                1              13       1      0    0      1   \n",
       "118     3.9                0              25       1      1    0      0   \n",
       "\n",
       "     Description_Length  Competitor Count  Size_1 to 50 employees  ...  \\\n",
       "325               777.0                 0                       0  ...   \n",
       "674               345.0                 0                       0  ...   \n",
       "396               232.0                 0                       0  ...   \n",
       "895              1017.0                 3                       0  ...   \n",
       "859               575.0                 3                       0  ...   \n",
       "..                  ...               ...                     ...  ...   \n",
       "878               569.0                 0                       0  ...   \n",
       "80                319.0                 0                       0  ...   \n",
       "782               668.0                 0                       0  ...   \n",
       "745               420.0                 0                       0  ...   \n",
       "118               734.0                 3                       0  ...   \n",
       "\n",
       "     Job Categories_Other  Job Categories_Other Engineer  \\\n",
       "325                     0                              0   \n",
       "674                     0                              0   \n",
       "396                     0                              0   \n",
       "895                     0                              0   \n",
       "859                     0                              0   \n",
       "..                    ...                            ...   \n",
       "878                     0                              0   \n",
       "80                      1                              0   \n",
       "782                     0                              0   \n",
       "745                     0                              0   \n",
       "118                     0                              0   \n",
       "\n",
       "     Job Categories_Software Engineer  Seniority_Junior  Seniority_Senior  \\\n",
       "325                                 0                 0                 1   \n",
       "674                                 0                 0                 1   \n",
       "396                                 0                 0                 0   \n",
       "895                                 0                 0                 0   \n",
       "859                                 0                 0                 0   \n",
       "..                                ...               ...               ...   \n",
       "878                                 0                 0                 0   \n",
       "80                                  0                 0                 0   \n",
       "782                                 0                 0                 0   \n",
       "745                                 0                 0                 1   \n",
       "118                                 0                 0                 0   \n",
       "\n",
       "     Seniority_none  Revenue_Adj_Unknown / Non-Applicable  Revenue_Adj_big  \\\n",
       "325               0                                     1                0   \n",
       "674               0                                     0                1   \n",
       "396               1                                     1                0   \n",
       "895               1                                     0                1   \n",
       "859               1                                     0                1   \n",
       "..              ...                                   ...              ...   \n",
       "878               1                                     1                0   \n",
       "80                1                                     0                0   \n",
       "782               1                                     1                0   \n",
       "745               0                                     0                0   \n",
       "118               1                                     0                0   \n",
       "\n",
       "     Revenue_Adj_medium  Revenue_Adj_small  \n",
       "325                   0                  0  \n",
       "674                   0                  0  \n",
       "396                   0                  0  \n",
       "895                   0                  0  \n",
       "859                   0                  0  \n",
       "..                  ...                ...  \n",
       "878                   0                  0  \n",
       "80                    0                  1  \n",
       "782                   0                  0  \n",
       "745                   0                  1  \n",
       "118                   0                  1  \n",
       "\n",
       "[581 rows x 165 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_n2 = pd.get_dummies(df2.drop(['Job Title', 'Salary Estimate', 'Job Description',\n",
    "                               'Company Name','Location','Headquarters','Founded','Competitors',\n",
    "                               'Min_Salary','Max_Salary','Revenue'], axis=1))\n",
    "\n",
    "\n",
    "X2 = df_n2.drop(['Avg Salary', 'Size_-1','Sector_-1','Industry_-1'], axis=1)\n",
    "y2 = df_n2['Avg Salary'].values\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=777)\n",
    "\n",
    "X2_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = ['Rating', 'Age of Company', 'Description_Length', 'Competitor Count']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating                                 -1.018485e-16\n",
      "Is_Headquarters                         5.767285e-01\n",
      "Age of Company                         -2.883210e-17\n",
      "Python                                  5.278246e-01\n",
      "Spark                                   2.276560e-01\n",
      "                                            ...     \n",
      "Seniority_none                          6.964587e-01\n",
      "Revenue_Adj_Unknown / Non-Applicable    2.765599e-01\n",
      "Revenue_Adj_big                         3.220911e-01\n",
      "Revenue_Adj_medium                      8.094435e-02\n",
      "Revenue_Adj_small                       3.204047e-01\n",
      "Length: 166, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Standardization of train & test:\n",
    "\n",
    "standard = StandardScaler()\n",
    "normal = MinMaxScaler()\n",
    "\n",
    "X_test_stand = X_test.copy()\n",
    "X_train_stand = X_train.copy()\n",
    "y_train_stand = y_train.copy()\n",
    "y_test_stand = y_test.copy()\n",
    "\n",
    "\n",
    "X_train_stand[numerical_columns] = standard.fit_transform(X_train_stand[numerical_columns])\n",
    "X_test_stand[numerical_columns] = standard.transform(X_test_stand[numerical_columns])\n",
    "\n",
    "print(X_train_stand.mean(axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robust \n",
    "\n",
    "robust = RobustScaler()\n",
    "\n",
    "X_test_robust = X_test.copy()\n",
    "X_train_robust = X_train.copy()\n",
    "\n",
    "X_train_robust[numerical_columns] = robust.fit_transform(X_train_robust[numerical_columns])\n",
    "X_test_robust[numerical_columns] = robust.transform(X_test_robust[numerical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization of train & test:\n",
    "\n",
    "normal = MinMaxScaler()\n",
    "\n",
    "X_test_norm = X_test.copy()\n",
    "X_train_norm = X_train.copy()\n",
    "\n",
    "X_train_norm[numerical_columns] = normal.fit_transform(X_train_norm[numerical_columns])\n",
    "X_test_norm[numerical_columns] = normal.transform(X_test_norm[numerical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Model Scores:\n",
      "R-Squared Value: -0.007879122082713241\n",
      "Root Mean Square Error: 40.74573295143369\n"
     ]
    }
   ],
   "source": [
    "# our means of checking how well our model is doing hehe\n",
    "\n",
    "dummy_model = DummyRegressor()\n",
    "\n",
    "dummy_model.fit(X_train, y_train)\n",
    "\n",
    "R2 = dummy_model.score(X_test, y_test)\n",
    "\n",
    "y_predict = dummy_model.predict(X_test)\n",
    "\n",
    "RMSE = MSE(y_test, y_predict)**(0.5)\n",
    "\n",
    "print('Dummy Model Scores:')\n",
    "print(f'R-Squared Value: {R2}') \n",
    "print(f'Root Mean Square Error: {RMSE}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dummy model is taking the mean average salary and using that to \"predict\" the rest.\n",
    "Dummy models set the standard for what a bad model looks like.\n",
    "The R2 score is showing the percentage of accuracy of a model (from 0 to 1 mostly). When it is negative,\n",
    "it is showing that the model does NOT follow the trend, which would make sense for our dummy model. \n",
    "Clearly this is showing us a very \"bad\" model to set the standard for how our models are doing in terms\n",
    "of their RMSE scores. For this model, we are deviating by $40K, which we now know is a very poor score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Model Scores:\n",
      "R-Squared Value: -0.0034232925890058663\n",
      "Root Mean Square Error: 35.78505290868794\n"
     ]
    }
   ],
   "source": [
    "# our means of checking how well our model is doing hehe\n",
    "\n",
    "dummy_model2 = DummyRegressor()\n",
    "\n",
    "dummy_model2.fit(X2_train, y2_train)\n",
    "\n",
    "R22 = dummy_model2.score(X2_test, y2_test)\n",
    "\n",
    "y2_predict = dummy_model2.predict(X2_test)\n",
    "\n",
    "RMSE2 = MSE(y2_test, y2_predict)**(0.5)\n",
    "\n",
    "print('Dummy Model Scores:')\n",
    "print(f'R-Squared Value: {R22}') \n",
    "print(f'Root Mean Square Error: {RMSE2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae with outliers: -18.576540293468227\n",
      "mae with standarization: -126325529791.9111\n",
      "mae without outliers: -18.420703523105303\n",
      "r2 with outliers: 0.4145995408707575\n",
      "r2 without outliers: 0.36942922879481693\n",
      "r2 with standarization: -2.492221499320103e+20\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression Model\n",
    "#looked at rmse ,wondered why you switched ,im ok with it butg wanted to know\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "linear_reg1 = LinearRegression()\n",
    "linear_reg2 = LinearRegression()\n",
    "linear_reg3 = LinearRegression()\n",
    "linear_reg5 = LinearRegression()\n",
    "\n",
    "linear_reg1.fit(X_train,y_train)\n",
    "linear_reg2.fit(X_train_norm,y_train)\n",
    "linear_reg3.fit(X_train_stand,y_train)\n",
    "linear_reg5.fit(X2_train,y2_train)\n",
    "\n",
    "lrm = np.mean(cross_val_score(linear_reg1, X_train, y_train, scoring='neg_mean_absolute_error', cv=kf))\n",
    "\n",
    "norm_lrm = np.mean(cross_val_score(linear_reg2, X_train_norm, y_train, scoring='neg_mean_absolute_error', cv=kf))\n",
    "\n",
    "stand_lrm = np.mean(cross_val_score(linear_reg3, X_train_stand, y_train, scoring='neg_mean_absolute_error', cv=kf))\n",
    "\n",
    "out_lrm = np.mean(cross_val_score(linear_reg5, X2_train, y2_train, scoring='neg_mean_absolute_error', cv=kf))\n",
    "\n",
    "r2_lin= np.mean(cross_val_score(linear_reg1, X_train, y_train, cv=3))\n",
    "r2out = np.mean(cross_val_score(linear_reg5, X2_train, y2_train, cv=3))\n",
    "stand_r2 = np.mean(cross_val_score(linear_reg3, X_train_stand, y_train, cv=3))\n",
    "\n",
    "\n",
    "\n",
    "print(f\"mae with outliers: {lrm}\")\n",
    "\n",
    "print(f\"mae with standarization: {stand_lrm}\")\n",
    "\n",
    "print(f\"mae without outliers: {out_lrm}\")\n",
    "\n",
    "print(f\"r2 with outliers: {r2_lin}\")\n",
    "\n",
    "print(f\"r2 without outliers: {r2out}\")\n",
    "\n",
    "print(f\"r2 with standarization: {stand_r2}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we learned so far: \n",
    "\n",
    "-normalization of data for linear regression does not work! It creates a non-linear model\n",
    "\n",
    "-removing outliers actually negatively affects the performance of linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying feature selection so we can improve our score\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test,i):\n",
    "    \n",
    "    # configure to select a subset of features\n",
    "    fs = SelectKBest(score_func=f_regression, k=i)\n",
    "    \n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    \n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    \n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    \n",
    "    return X_train_fs, X_test_fs, fs\n",
    "\n",
    "# 64 is clearly the best rn\n",
    "#why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "r2arr=[]\n",
    "modelI=[]\n",
    "for i in range(1,167):\n",
    "    X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test,i)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_fs, y_train)\n",
    "\n",
    "    model_improved = np.mean(cross_val_score(model, X_train_fs, y_train, scoring='neg_mean_absolute_error', cv=3))\n",
    "    r2_improved= np.mean(cross_val_score(model, X_train_fs, y_train, cv=3))\n",
    "    r2arr.append(r2_improved)\n",
    "    modelI.append(model_improved)\n",
    "    np.seterr(invalid='ignore')\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best(arr,r):\n",
    "    maxn=-100\n",
    "    maxI=0\n",
    "    for i in range(r):\n",
    "        if(maxn<arr[i]):\n",
    "            maxn=arr[i]\n",
    "            maxI=i+1\n",
    "    return maxI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "#note the index is the same for both r2 and mae so it doesnt matter which we use\n",
    "maxIr2=find_best(r2arr,166)\n",
    "print(maxIr2)\n",
    "\n",
    "maxIm=find_best(modelI,166)\n",
    "print(maxIm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test,64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-18.398649554620963\n",
      "0.5165190399847649\n"
     ]
    }
   ],
   "source": [
    "# improving our linear regression score with automatic feature selection\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_fs, y_train)\n",
    "\n",
    "model_improved = np.mean(cross_val_score(model, X_train_fs, y_train, scoring='neg_mean_absolute_error', cv=3))\n",
    "r2_improved= np.mean(cross_val_score(model, X_train_fs, y_train, cv=3))\n",
    "\n",
    "\n",
    "print(model_improved)\n",
    "print(r2_improved)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After trying several values, we found that 64 of the \"best\" features creates the most accurate model\n",
    "\n",
    "Our score definitely improved, but it appears that this model may not be our best bet. Let's try others!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Job Categories_Data Analyst                  0.393697\n",
       "Job Categories_Data Scientist                0.345837\n",
       "Seniority_Senior                             0.344446\n",
       "Seniority_none                               0.335689\n",
       "Python                                       0.330520\n",
       "State_ CA                                    0.302434\n",
       "Job Categories_Director                      0.255496\n",
       "Type of ownership_Nonprofit Organization     0.200887\n",
       "Salary_Per_Hour_annually                     0.193550\n",
       "Salary_Per_Hour_hourly                       0.193550\n",
       "Sector_Information Technology                0.185860\n",
       "Job Categories_Other                         0.172034\n",
       "AWS                                          0.172008\n",
       "Spark                                        0.164927\n",
       "Sector_Health Care                           0.147159\n",
       "Industry_Health Care Services & Hospitals    0.147159\n",
       "Industry_Food & Beverage Manufacturing       0.136895\n",
       "Rating                                       0.128693\n",
       "Industry_Financial Analytics & Research      0.125312\n",
       "Type of ownership_Company - Public           0.125190\n",
       "Industry_Internet                            0.124602\n",
       "State_ AL                                    0.123517\n",
       "Size_501 to 1000 employees                   0.120963\n",
       "Revenue_Adj_medium                           0.116913\n",
       "Type of ownership_Hospital                   0.114540\n",
       "Name: Avg Salary, dtype: float64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are the most correlated variables?\n",
    "\n",
    "df3 = pd.get_dummies(df2.drop(['Job Title', 'Salary Estimate', 'Job Description',\n",
    "                               'Company Name','Location','Headquarters','Founded','Competitors',\n",
    "                               'Min_Salary','Max_Salary','Revenue'], axis=1))\n",
    "corr_matrix = df3.corr()\n",
    "corr_matrix['Avg Salary'].sort_values(ascending=False)\n",
    "\n",
    "correlations = abs(corr_matrix['Avg Salary']).sort_values(ascending=False)\n",
    "correlations.drop('Avg Salary', inplace=True)\n",
    "correlations.head(25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regression Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae with outliers: -19.64814501875747\n",
      "mae without outliers: -20.682212851177947\n",
      "mae norm: -19.644701850993766\n",
      "mae stand: -19.647148700345543\n",
      "r2 with outliers: 0.47435324601345724\n",
      "r2 without outliers: 0.43388910630860567\n",
      "r2 norm: 0.4743342479976158\n",
      "r2 stand: 0.4747883632042346\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso_reg = Lasso(alpha=0.1)\n",
    "lasso_reg2 = Lasso(alpha=0.1)\n",
    "lasso_reg3 = Lasso(alpha=0.1)\n",
    "lasso_reg4 = Lasso(alpha=0.1)\n",
    "\n",
    "\n",
    "lasso_reg.fit(X_train,y_train)\n",
    "lasso_reg2.fit(X2_train,y2_train)\n",
    "lasso_reg3.fit(X_train_norm, y_train)\n",
    "lasso_reg4.fit(X_train_stand, y_train)\n",
    "\n",
    "\n",
    "lasso1 = np.mean(cross_val_score(lasso_reg, X_train, y_train, scoring='neg_mean_absolute_error', cv=3))\n",
    "\n",
    "lasso2 = np.mean(cross_val_score(lasso_reg2, X2_train, y2_train, scoring='neg_mean_absolute_error', cv=3))\n",
    "\n",
    "lasso3 = np.mean(cross_val_score(lasso_reg3, X_train_norm, y_train, scoring='neg_mean_absolute_error', cv=3))\n",
    "\n",
    "lasso4 = np.mean(cross_val_score(lasso_reg4, X_train_stand, y_train, scoring='neg_mean_absolute_error', cv=3))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lasso1_r2 = np.mean(cross_val_score(lasso_reg, X_train, y_train, cv=3))\n",
    "\n",
    "lasso2_r2 = np.mean(cross_val_score(lasso_reg2, X2_train, y2_train, cv=3))\n",
    "\n",
    "lasso3_r2 = np.mean(cross_val_score(lasso_reg3, X_train_norm, y_train, cv=3))\n",
    "\n",
    "lasso4_r2 = np.mean(cross_val_score(lasso_reg4, X_train_stand, y_train, cv=3))\n",
    "\n",
    "\n",
    "\n",
    "print(f\"mae with outliers: {lasso1}\")\n",
    "\n",
    "print(f\"mae without outliers: {lasso2}\")\n",
    "\n",
    "print(f\"mae norm: {lasso3}\")\n",
    "\n",
    "print(f\"mae stand: {lasso4}\")\n",
    "\n",
    "\n",
    "print(f\"r2 with outliers: {lasso1_r2}\")\n",
    "\n",
    "print(f\"r2 without outliers: {lasso2_r2}\")\n",
    "\n",
    "print(f\"r2 norm: {lasso3_r2}\")\n",
    "\n",
    "print(f\"r2 stand: {lasso4_r2}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the error is around the same as linear regression but the r2 score is better. \n",
    "standarization/normalization aren't making much of a difference\n",
    "\n",
    "Let's see if feature engineering can optimize it. We will once again work with the model with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features2(X_train, y_train, X_test):\n",
    "    \n",
    "    # configure to select a subset of features\n",
    "    fs = SelectKBest(score_func=f_regression, k=53)\n",
    "    \n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    \n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    \n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    \n",
    "    return X_train_fs, X_test_fs, fs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fs2, X_test_fs2, fs2 = select_features2(X_train, y_train, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-19.315385896769133\n",
      "0.4995811863608683\n"
     ]
    }
   ],
   "source": [
    "model2 = Lasso(alpha=0.1)\n",
    "model2.fit(X_train_fs2, y_train)\n",
    "\n",
    "model2_improved = np.mean(cross_val_score(model2, X_train_fs2, y_train, scoring='neg_mean_absolute_error', cv=3))\n",
    "r2_improved2= np.mean(cross_val_score(model2, X_train_fs2, y_train, cv=3))\n",
    "\n",
    "\n",
    "print(model2_improved)\n",
    "print(r2_improved2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "53 is our best score in this feature selection. \n",
    "\n",
    "the linear model is currently doing better with the feature selection.\n",
    "\n",
    "let's see if there is anything else we can do to improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>error</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02</td>\n",
       "      <td>-18.780318</td>\n",
       "      <td>0.512834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alpha      error        r2\n",
       "1   0.02 -18.780318  0.512834"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#need explenation\n",
    "alpha = []\n",
    "error = []\n",
    "r2 = []\n",
    "\n",
    "for i in range (1,100):\n",
    "    alpha.append(i/100)\n",
    "    lasso = Lasso(alpha=(i/100))\n",
    "    lasso.fit(X_train_fs2, y_train)\n",
    "    error.append(np.mean(cross_val_score(lasso, X_train_fs2, y_train, scoring='neg_mean_absolute_error', cv=3)))\n",
    "    r2.append(np.mean(cross_val_score(lasso, X_train_fs2, y_train, cv=3)))\n",
    "    \n",
    "score = tuple(zip(alpha,error,r2))\n",
    "df_score = pd.DataFrame(score, columns = ['alpha','error','r2'])\n",
    "\n",
    "df_score[df_score.r2 == max(df_score.r2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is our most optimized. linear regression is doing better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae with outliers: -13.155349281609194\n",
      "mae without outliers: -13.394481896551724\n",
      "mae norm: -13.311669109195403\n",
      "mae stand: -13.16576264367816\n",
      "mae robust: -13.397691235632186\n",
      "r2 with outliers: 0.6320559690712425\n",
      "r2 without outliers: 0.6448510168806203\n",
      "r2 norm: 0.6338704248495645\n",
      "r2 stand: 0.6352062450179607\n",
      "r2 robust: 0.6374811817788455\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "\n",
    "forest_reg = RFR()\n",
    "forest_reg2 = RFR()\n",
    "forest_reg3 = RFR()\n",
    "forest_reg4 = RFR()\n",
    "forest_reg5 = RFR()\n",
    "\n",
    "\n",
    "forest_reg.fit(X_train,y_train)\n",
    "forest_reg2.fit(X2_train,y2_train)\n",
    "forest_reg3.fit(X_train_norm, y_train)\n",
    "forest_reg4.fit(X_train_stand, y_train)\n",
    "forest_reg5.fit(X_train_robust, y_train)\n",
    "\n",
    "\n",
    "\n",
    "forest1 = np.mean(cross_val_score(forest_reg, X_train, y_train, scoring='neg_mean_absolute_error', cv=kf))\n",
    "\n",
    "forest2 = np.mean(cross_val_score(forest_reg2, X2_train, y2_train, scoring='neg_mean_absolute_error', cv=kf))\n",
    "\n",
    "forest3 = np.mean(cross_val_score(forest_reg3, X_train_norm, y_train, scoring='neg_mean_absolute_error', cv=kf))\n",
    "\n",
    "forest4 = np.mean(cross_val_score(forest_reg4, X_train_stand, y_train, scoring='neg_mean_absolute_error', cv=kf))\n",
    "\n",
    "forest5 = np.mean(cross_val_score(forest_reg5, X_train_robust, y_train, scoring='neg_mean_absolute_error', cv=kf))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "forest1_r2 = np.mean(cross_val_score(forest_reg, X_train, y_train, cv=kf))\n",
    "\n",
    "forest2_r2 = np.mean(cross_val_score(forest_reg2, X2_train, y2_train, cv=kf))\n",
    "\n",
    "forest3_r2 = np.mean(cross_val_score(forest_reg3, X_train_norm, y_train, cv=kf))\n",
    "\n",
    "forest4_r2 = np.mean(cross_val_score(forest_reg4, X_train_stand, y_train, cv=kf))\n",
    "\n",
    "forest5_r2 = np.mean(cross_val_score(forest_reg5, X_train_robust, y_train, cv=kf))\n",
    "\n",
    "\n",
    "\n",
    "print(f\"mae with outliers: {forest1}\")\n",
    "\n",
    "print(f\"mae without outliers: {forest2}\")\n",
    "\n",
    "print(f\"mae norm: {forest3}\")\n",
    "\n",
    "print(f\"mae stand: {forest4}\")\n",
    "\n",
    "print(f\"mae robust: {forest5}\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"r2 with outliers: {forest1_r2}\")\n",
    "\n",
    "print(f\"r2 without outliers: {forest2_r2}\")\n",
    "\n",
    "print(f\"r2 norm: {forest3_r2}\")\n",
    "\n",
    "print(f\"r2 stand: {forest4_r2}\")\n",
    "\n",
    "print(f\"r2 robust: {forest5_r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features3(X_train, y_train, X_test,i):\n",
    "    \n",
    "    # configure to select a subset of features\n",
    "    fs = SelectKBest(score_func=f_regression, k=i)\n",
    "    \n",
    "    # learn relationship from training data\n",
    "    fs.fit(X_train, y_train)\n",
    "    \n",
    "    # transform train input data\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    \n",
    "    # transform test input data\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    \n",
    "    return X_train_fs, X_test_fs, fs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "r2arr3=[]\n",
    "modelI3=[]\n",
    "for i in range(1,167):\n",
    "    X_train_fs3, X_test_fs3, fs3 = select_features(X_train, y_train, X_test,i)\n",
    "    model3 = RFR()\n",
    "    model3.fit(X_train_fs3, y_train)\n",
    "\n",
    "    model3_improved = np.mean(cross_val_score(model3, X_train_fs3, y_train, scoring='neg_mean_absolute_error', cv=kf))\n",
    "    r2_improved3= np.mean(cross_val_score(model3, X_train_fs3, y_train, cv=3))\n",
    "\n",
    "    r2arr3.append(r2_improved3)\n",
    "    modelI3.append(model3_improved)\n",
    "    np.seterr(invalid='ignore')\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "135\n"
     ]
    }
   ],
   "source": [
    "#note the index is not the same for r2 and mae so i will use different ones for both methods\n",
    "maxIr2=find_best(r2arr3,166)\n",
    "print(maxIr2)\n",
    "\n",
    "maxIm=find_best(modelI3,166)\n",
    "print(maxIm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for r2\n",
    "X_train_fs3m, X_test_fs3m, fs3m = select_features3(X_train, y_train, X_test,25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-13.373745047242826\n",
      "0.627377780486283\n"
     ]
    }
   ],
   "source": [
    "model3 = RFR()\n",
    "model3.fit(X_train_fs3m, y_train)\n",
    "\n",
    "model3_improved = np.mean(cross_val_score(model3, X_train_fs3m, y_train, scoring='neg_mean_absolute_error', cv=kf))\n",
    "r2_improved3= np.mean(cross_val_score(model3, X_train_fs3m, y_train, cv=3))\n",
    "\n",
    "\n",
    "print(model3_improved)\n",
    "print(r2_improved3)\n",
    "\n",
    "# 156 - 14.744172520466938\n",
    "\n",
    "# 164 - \n",
    "#-14.748348608761047\n",
    "#0.6102484997748273\n",
    "\n",
    "#163?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for mae\n",
    "X_train_fs3r, X_test_fs3r, fs3r = select_features3(X_train, y_train, X_test,135)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-13.139881465517243\n",
      "0.6178703463653711\n"
     ]
    }
   ],
   "source": [
    "model3 = RFR()\n",
    "model3.fit(X_train_fs3r, y_train)\n",
    "\n",
    "model3_improved = np.mean(cross_val_score(model3, X_train_fs3r, y_train, scoring='neg_mean_absolute_error', cv=kf))\n",
    "r2_improved3= np.mean(cross_val_score(model3, X_train_fs3r, y_train, cv=3))\n",
    "\n",
    "\n",
    "print(model3_improved)\n",
    "print(r2_improved3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RFR()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train,y_train)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestRegressor(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 400,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': None,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestRegressor(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random2 = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "rf_random2.fit(X_train_robust,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 400,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': None,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 400,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': None,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass groups=[155.   161.5   80.5   85.5  139.5  113.    96.5   81.    98.   173.\n",
      "  92.   145.    62.5   95.5  143.5   52.5  139.   142.5  138.5  143.\n",
      "  59.    76.5  120.   107.    91.    60.    64.   154.5   82.   140.\n",
      " 124.   130.    51.5   47.    97.   124.5  114.5  106.   113.5   83.5\n",
      "  80.    81.    65.    87.5   73.   116.5   99.    85.5   73.    94.5\n",
      "  85.5  112.5  101.    53.75  77.5  184.5  155.   115.    50.    53.75\n",
      " 114.5  147.   140.5  102.5   73.    80.5   79.5   74.    54.    61.\n",
      " 254.    87.    43.   106.5   69.    71.    92.    91.5  171.5  172.\n",
      " 124.5  118.   128.    64.   121.    48.    56.5  142.    86.5  148.\n",
      "  97.5   71.5   48.    86.5   67.   162.   120.    65.5   94.5  109.\n",
      " 153.    77.5   53.   143.   127.5   29.5   64.   102.5  140.   119.\n",
      " 114.5   52.5   62.   115.5  107.5   90.    95.    64.    61.    76.\n",
      "  89.   162.    68.5   87.   106.5   76.    99.   142.5   68.   100.\n",
      " 154.5   94.5   77.5   97.    78.   146.5   87.5   66.5  169.   114.\n",
      " 113.5   76.5  155.    68.75  94.5   54.   121.5  107.    81.   130.\n",
      "  56.5   84.5  117.5   58.5  163.   106.5  106.5   45.5  122.    81.\n",
      " 117.5   98.    33.75 169.    62.5   45.5   86.5  107.5   68.75  59.5\n",
      "  63.   154.5  103.5   61.    70.5   85.5   81.    66.25 107.5   81.\n",
      " 117.5  140.    72.5  120.   137.    84.5  128.5   51.25 109.   139.\n",
      "  48.5   88.5   62.5  110.5  122.5  120.   142.5  115.    92.5   62.\n",
      " 109.5   85.   100.    87.5   94.5   95.5   73.5  110.    44.   103.\n",
      " 128.5  102.5  111.5   85.    85.   118.5   98.   112.   181.    65.5\n",
      "  91.    75.5   53.5   69.5  132.5   87.   101.   120.5  128.5  107.5\n",
      "  69.5   62.5   77.5  122.   171.5   87.   139.5   74.   136.5   61.5\n",
      "  61.    85.   114.   107.5   73.5   70.5  221.5  205.    37.5   37.5\n",
      " 134.    99.    68.75 154.5  121.    51.   123.5  165.   114.5   53.75\n",
      " 151.5   86.5   96.    95.   168.   114.   122.5   62.5   61.5   84.5\n",
      "  56.5   90.    77.5  138.5   80.5   92.5   58.   149.5  134.5  150.5\n",
      "  55.    98.5   99.5   96.5   60.5  134.5  147.   142.5   61.    81.\n",
      " 173.   114.5   48.5   84.5   92.   115.    61.    98.5   75.5   94.\n",
      "  70.    85.    51.5  120.   173.   121.    87.5  140.5   84.5  161.5\n",
      "  65.5  113.5   87.   111.5  109.5   87.5  116.5  104.5  123.5   96.5\n",
      "  97.5  119.5   95.    44.   140.    73.5  105.5   15.5   71.5  108.\n",
      "  99.5   62.    65.    79.5   87.5  142.    93.5   50.   150.5  124.5\n",
      "  72.    84.5  112.5   56.5  180.   194.5  107.    94.5   76.5   64.5\n",
      " 107.    76.5   90.5  112.5  107.5  136.5   87.5   70.5  111.   134.5\n",
      "  84.   140.5   60.   124.    76.5   74.    59.    96.    66.25 164.\n",
      " 114.5   85.    83.    78.75 163.5  120.   153.    61.   113.5  112.5\n",
      "  77.5   98.   121.   100.5   85.5   61.5  105.   180.    74.5  120.\n",
      " 137.   120.    98.5   66.5   65.5  105.5  108.    63.    67.    93.\n",
      "  80.    73.5  121.   111.5   71.5  104.5   70.5  139.5  103.5  139.5\n",
      " 115.5   80.   205.   147.5   71.   138.5  103.    79.    78.75  54.\n",
      "  95.   110.5  124.   107.    70.5   70.   109.5   87.    66.5   60.\n",
      "  90.    82.    92.5   81.   100.   137.    73.5   85.   147.    62.5\n",
      " 104.5  110.    85.    65.5   85.5  113.    84.5  128.   120.5   51.5\n",
      " 124.5   70.5   87.5  169.    98.5   47.5  151.5  121.   132.5   80.\n",
      "  81.    96.   225.    84.    66.5   33.75  88.   153.   100.    51.\n",
      " 109.    72.5   53.5   63.5   99.   145.5   99.    68.5  164.5   87.5\n",
      " 109.   194.5  162.5  162.   129.5  133.   107.    52.5  143.5   92.\n",
      " 167.5  148.   101.5  102.    68.5  128.5  129.5   62.5   85.   167.5\n",
      " 110.5  125.   107.   154.5  105.5  154.5   52.5  133.    66.25  63.5\n",
      " 124.    76.5   53.75 115.   157.   174.   130.    84.   168.   164.5\n",
      "  39.5  205.    54.   112.5  140.    84.5   53.5  147.    61.5   96.\n",
      " 109.   153.5   81.    92.    72.   130.   111.5  106.5   95.    81.\n",
      " 140.   124.    47.    59.   132.5  119.   120.    49.   142.    85.\n",
      "  52.5   84.   110.   167.5   90.   177.   100.    51.5  161.5   61.5\n",
      "  73.   102.    69.5   91.5  107.5  107.    68.75  49.   107.    70.5\n",
      " 149.5   47.    98.    93.5  133.   117.5  100.   101.    64.5  114.\n",
      " 114.5   66.   110.5   77.   128.5  143.5  107.5   44.5   68.5  179.5\n",
      "  83.    91.5  237.5 ] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Users\\Avi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass groups=[155.   161.5   80.5   85.5  139.5  113.    96.5   81.    98.   173.\n",
      "  92.   145.    62.5   95.5  143.5   52.5  139.   142.5  138.5  143.\n",
      "  59.    76.5  120.   107.    91.    60.    64.   154.5   82.   140.\n",
      " 124.   130.    51.5   47.    97.   124.5  114.5  106.   113.5   83.5\n",
      "  80.    81.    65.    87.5   73.   116.5   99.    85.5   73.    94.5\n",
      "  85.5  112.5  101.    53.75  77.5  184.5  155.   115.    50.    53.75\n",
      " 114.5  147.   140.5  102.5   73.    80.5   79.5   74.    54.    61.\n",
      " 254.    87.    43.   106.5   69.    71.    92.    91.5  171.5  172.\n",
      " 124.5  118.   128.    64.   121.    48.    56.5  142.    86.5  148.\n",
      "  97.5   71.5   48.    86.5   67.   162.   120.    65.5   94.5  109.\n",
      " 153.    77.5   53.   143.   127.5   29.5   64.   102.5  140.   119.\n",
      " 114.5   52.5   62.   115.5  107.5   90.    95.    64.    61.    76.\n",
      "  89.   162.    68.5   87.   106.5   76.    99.   142.5   68.   100.\n",
      " 154.5   94.5   77.5   97.    78.   146.5   87.5   66.5  169.   114.\n",
      " 113.5   76.5  155.    68.75  94.5   54.   121.5  107.    81.   130.\n",
      "  56.5   84.5  117.5   58.5  163.   106.5  106.5   45.5  122.    81.\n",
      " 117.5   98.    33.75 169.    62.5   45.5   86.5  107.5   68.75  59.5\n",
      "  63.   154.5  103.5   61.    70.5   85.5   81.    66.25 107.5   81.\n",
      " 117.5  140.    72.5  120.   137.    84.5  128.5   51.25 109.   139.\n",
      "  48.5   88.5   62.5  110.5  122.5  120.   142.5  115.    92.5   62.\n",
      " 109.5   85.   100.    87.5   94.5   95.5   73.5  110.    44.   103.\n",
      " 128.5  102.5  111.5   85.    85.   118.5   98.   112.   181.    65.5\n",
      "  91.    75.5   53.5   69.5  132.5   87.   101.   120.5  128.5  107.5\n",
      "  69.5   62.5   77.5  122.   171.5   87.   139.5   74.   136.5   61.5\n",
      "  61.    85.   114.   107.5   73.5   70.5  221.5  205.    37.5   37.5\n",
      " 134.    99.    68.75 154.5  121.    51.   123.5  165.   114.5   53.75\n",
      " 151.5   86.5   96.    95.   168.   114.   122.5   62.5   61.5   84.5\n",
      "  56.5   90.    77.5  138.5   80.5   92.5   58.   149.5  134.5  150.5\n",
      "  55.    98.5   99.5   96.5   60.5  134.5  147.   142.5   61.    81.\n",
      " 173.   114.5   48.5   84.5   92.   115.    61.    98.5   75.5   94.\n",
      "  70.    85.    51.5  120.   173.   121.    87.5  140.5   84.5  161.5\n",
      "  65.5  113.5   87.   111.5  109.5   87.5  116.5  104.5  123.5   96.5\n",
      "  97.5  119.5   95.    44.   140.    73.5  105.5   15.5   71.5  108.\n",
      "  99.5   62.    65.    79.5   87.5  142.    93.5   50.   150.5  124.5\n",
      "  72.    84.5  112.5   56.5  180.   194.5  107.    94.5   76.5   64.5\n",
      " 107.    76.5   90.5  112.5  107.5  136.5   87.5   70.5  111.   134.5\n",
      "  84.   140.5   60.   124.    76.5   74.    59.    96.    66.25 164.\n",
      " 114.5   85.    83.    78.75 163.5  120.   153.    61.   113.5  112.5\n",
      "  77.5   98.   121.   100.5   85.5   61.5  105.   180.    74.5  120.\n",
      " 137.   120.    98.5   66.5   65.5  105.5  108.    63.    67.    93.\n",
      "  80.    73.5  121.   111.5   71.5  104.5   70.5  139.5  103.5  139.5\n",
      " 115.5   80.   205.   147.5   71.   138.5  103.    79.    78.75  54.\n",
      "  95.   110.5  124.   107.    70.5   70.   109.5   87.    66.5   60.\n",
      "  90.    82.    92.5   81.   100.   137.    73.5   85.   147.    62.5\n",
      " 104.5  110.    85.    65.5   85.5  113.    84.5  128.   120.5   51.5\n",
      " 124.5   70.5   87.5  169.    98.5   47.5  151.5  121.   132.5   80.\n",
      "  81.    96.   225.    84.    66.5   33.75  88.   153.   100.    51.\n",
      " 109.    72.5   53.5   63.5   99.   145.5   99.    68.5  164.5   87.5\n",
      " 109.   194.5  162.5  162.   129.5  133.   107.    52.5  143.5   92.\n",
      " 167.5  148.   101.5  102.    68.5  128.5  129.5   62.5   85.   167.5\n",
      " 110.5  125.   107.   154.5  105.5  154.5   52.5  133.    66.25  63.5\n",
      " 124.    76.5   53.75 115.   157.   174.   130.    84.   168.   164.5\n",
      "  39.5  205.    54.   112.5  140.    84.5   53.5  147.    61.5   96.\n",
      " 109.   153.5   81.    92.    72.   130.   111.5  106.5   95.    81.\n",
      " 140.   124.    47.    59.   132.5  119.   120.    49.   142.    85.\n",
      "  52.5   84.   110.   167.5   90.   177.   100.    51.5  161.5   61.5\n",
      "  73.   102.    69.5   91.5  107.5  107.    68.75  49.   107.    70.5\n",
      " 149.5   47.    98.    93.5  133.   117.5  100.   101.    64.5  114.\n",
      " 114.5   66.   110.5   77.   128.5  143.5  107.5   44.5   68.5  179.5\n",
      "  83.    91.5  237.5 ] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-14.145581896551723\n",
      "0.591591019018949\n"
     ]
    }
   ],
   "source": [
    "base_model = RFR(n_estimators = 10, random_state = 42)\n",
    "base_model.fit(X_train,y_train)\n",
    "\n",
    "base_model_mae = np.mean(cross_val_score(base_model, X_train,y_train, y_train, scoring='neg_mean_absolute_error', cv=kf))\n",
    "r2_improvedB= np.mean(cross_val_score(base_model, X_train,y_train, y_train, cv=kf))\n",
    "\n",
    "\n",
    "\n",
    "print(base_model_mae)\n",
    "print(r2_improvedB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass groups=[155.   161.5   80.5   85.5  139.5  113.    96.5   81.    98.   173.\n",
      "  92.   145.    62.5   95.5  143.5   52.5  139.   142.5  138.5  143.\n",
      "  59.    76.5  120.   107.    91.    60.    64.   154.5   82.   140.\n",
      " 124.   130.    51.5   47.    97.   124.5  114.5  106.   113.5   83.5\n",
      "  80.    81.    65.    87.5   73.   116.5   99.    85.5   73.    94.5\n",
      "  85.5  112.5  101.    53.75  77.5  184.5  155.   115.    50.    53.75\n",
      " 114.5  147.   140.5  102.5   73.    80.5   79.5   74.    54.    61.\n",
      " 254.    87.    43.   106.5   69.    71.    92.    91.5  171.5  172.\n",
      " 124.5  118.   128.    64.   121.    48.    56.5  142.    86.5  148.\n",
      "  97.5   71.5   48.    86.5   67.   162.   120.    65.5   94.5  109.\n",
      " 153.    77.5   53.   143.   127.5   29.5   64.   102.5  140.   119.\n",
      " 114.5   52.5   62.   115.5  107.5   90.    95.    64.    61.    76.\n",
      "  89.   162.    68.5   87.   106.5   76.    99.   142.5   68.   100.\n",
      " 154.5   94.5   77.5   97.    78.   146.5   87.5   66.5  169.   114.\n",
      " 113.5   76.5  155.    68.75  94.5   54.   121.5  107.    81.   130.\n",
      "  56.5   84.5  117.5   58.5  163.   106.5  106.5   45.5  122.    81.\n",
      " 117.5   98.    33.75 169.    62.5   45.5   86.5  107.5   68.75  59.5\n",
      "  63.   154.5  103.5   61.    70.5   85.5   81.    66.25 107.5   81.\n",
      " 117.5  140.    72.5  120.   137.    84.5  128.5   51.25 109.   139.\n",
      "  48.5   88.5   62.5  110.5  122.5  120.   142.5  115.    92.5   62.\n",
      " 109.5   85.   100.    87.5   94.5   95.5   73.5  110.    44.   103.\n",
      " 128.5  102.5  111.5   85.    85.   118.5   98.   112.   181.    65.5\n",
      "  91.    75.5   53.5   69.5  132.5   87.   101.   120.5  128.5  107.5\n",
      "  69.5   62.5   77.5  122.   171.5   87.   139.5   74.   136.5   61.5\n",
      "  61.    85.   114.   107.5   73.5   70.5  221.5  205.    37.5   37.5\n",
      " 134.    99.    68.75 154.5  121.    51.   123.5  165.   114.5   53.75\n",
      " 151.5   86.5   96.    95.   168.   114.   122.5   62.5   61.5   84.5\n",
      "  56.5   90.    77.5  138.5   80.5   92.5   58.   149.5  134.5  150.5\n",
      "  55.    98.5   99.5   96.5   60.5  134.5  147.   142.5   61.    81.\n",
      " 173.   114.5   48.5   84.5   92.   115.    61.    98.5   75.5   94.\n",
      "  70.    85.    51.5  120.   173.   121.    87.5  140.5   84.5  161.5\n",
      "  65.5  113.5   87.   111.5  109.5   87.5  116.5  104.5  123.5   96.5\n",
      "  97.5  119.5   95.    44.   140.    73.5  105.5   15.5   71.5  108.\n",
      "  99.5   62.    65.    79.5   87.5  142.    93.5   50.   150.5  124.5\n",
      "  72.    84.5  112.5   56.5  180.   194.5  107.    94.5   76.5   64.5\n",
      " 107.    76.5   90.5  112.5  107.5  136.5   87.5   70.5  111.   134.5\n",
      "  84.   140.5   60.   124.    76.5   74.    59.    96.    66.25 164.\n",
      " 114.5   85.    83.    78.75 163.5  120.   153.    61.   113.5  112.5\n",
      "  77.5   98.   121.   100.5   85.5   61.5  105.   180.    74.5  120.\n",
      " 137.   120.    98.5   66.5   65.5  105.5  108.    63.    67.    93.\n",
      "  80.    73.5  121.   111.5   71.5  104.5   70.5  139.5  103.5  139.5\n",
      " 115.5   80.   205.   147.5   71.   138.5  103.    79.    78.75  54.\n",
      "  95.   110.5  124.   107.    70.5   70.   109.5   87.    66.5   60.\n",
      "  90.    82.    92.5   81.   100.   137.    73.5   85.   147.    62.5\n",
      " 104.5  110.    85.    65.5   85.5  113.    84.5  128.   120.5   51.5\n",
      " 124.5   70.5   87.5  169.    98.5   47.5  151.5  121.   132.5   80.\n",
      "  81.    96.   225.    84.    66.5   33.75  88.   153.   100.    51.\n",
      " 109.    72.5   53.5   63.5   99.   145.5   99.    68.5  164.5   87.5\n",
      " 109.   194.5  162.5  162.   129.5  133.   107.    52.5  143.5   92.\n",
      " 167.5  148.   101.5  102.    68.5  128.5  129.5   62.5   85.   167.5\n",
      " 110.5  125.   107.   154.5  105.5  154.5   52.5  133.    66.25  63.5\n",
      " 124.    76.5   53.75 115.   157.   174.   130.    84.   168.   164.5\n",
      "  39.5  205.    54.   112.5  140.    84.5   53.5  147.    61.5   96.\n",
      " 109.   153.5   81.    92.    72.   130.   111.5  106.5   95.    81.\n",
      " 140.   124.    47.    59.   132.5  119.   120.    49.   142.    85.\n",
      "  52.5   84.   110.   167.5   90.   177.   100.    51.5  161.5   61.5\n",
      "  73.   102.    69.5   91.5  107.5  107.    68.75  49.   107.    70.5\n",
      " 149.5   47.    98.    93.5  133.   117.5  100.   101.    64.5  114.\n",
      " 114.5   66.   110.5   77.   128.5  143.5  107.5   44.5   68.5  179.5\n",
      "  83.    91.5  237.5 ] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Users\\Avi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass groups=[155.   161.5   80.5   85.5  139.5  113.    96.5   81.    98.   173.\n",
      "  92.   145.    62.5   95.5  143.5   52.5  139.   142.5  138.5  143.\n",
      "  59.    76.5  120.   107.    91.    60.    64.   154.5   82.   140.\n",
      " 124.   130.    51.5   47.    97.   124.5  114.5  106.   113.5   83.5\n",
      "  80.    81.    65.    87.5   73.   116.5   99.    85.5   73.    94.5\n",
      "  85.5  112.5  101.    53.75  77.5  184.5  155.   115.    50.    53.75\n",
      " 114.5  147.   140.5  102.5   73.    80.5   79.5   74.    54.    61.\n",
      " 254.    87.    43.   106.5   69.    71.    92.    91.5  171.5  172.\n",
      " 124.5  118.   128.    64.   121.    48.    56.5  142.    86.5  148.\n",
      "  97.5   71.5   48.    86.5   67.   162.   120.    65.5   94.5  109.\n",
      " 153.    77.5   53.   143.   127.5   29.5   64.   102.5  140.   119.\n",
      " 114.5   52.5   62.   115.5  107.5   90.    95.    64.    61.    76.\n",
      "  89.   162.    68.5   87.   106.5   76.    99.   142.5   68.   100.\n",
      " 154.5   94.5   77.5   97.    78.   146.5   87.5   66.5  169.   114.\n",
      " 113.5   76.5  155.    68.75  94.5   54.   121.5  107.    81.   130.\n",
      "  56.5   84.5  117.5   58.5  163.   106.5  106.5   45.5  122.    81.\n",
      " 117.5   98.    33.75 169.    62.5   45.5   86.5  107.5   68.75  59.5\n",
      "  63.   154.5  103.5   61.    70.5   85.5   81.    66.25 107.5   81.\n",
      " 117.5  140.    72.5  120.   137.    84.5  128.5   51.25 109.   139.\n",
      "  48.5   88.5   62.5  110.5  122.5  120.   142.5  115.    92.5   62.\n",
      " 109.5   85.   100.    87.5   94.5   95.5   73.5  110.    44.   103.\n",
      " 128.5  102.5  111.5   85.    85.   118.5   98.   112.   181.    65.5\n",
      "  91.    75.5   53.5   69.5  132.5   87.   101.   120.5  128.5  107.5\n",
      "  69.5   62.5   77.5  122.   171.5   87.   139.5   74.   136.5   61.5\n",
      "  61.    85.   114.   107.5   73.5   70.5  221.5  205.    37.5   37.5\n",
      " 134.    99.    68.75 154.5  121.    51.   123.5  165.   114.5   53.75\n",
      " 151.5   86.5   96.    95.   168.   114.   122.5   62.5   61.5   84.5\n",
      "  56.5   90.    77.5  138.5   80.5   92.5   58.   149.5  134.5  150.5\n",
      "  55.    98.5   99.5   96.5   60.5  134.5  147.   142.5   61.    81.\n",
      " 173.   114.5   48.5   84.5   92.   115.    61.    98.5   75.5   94.\n",
      "  70.    85.    51.5  120.   173.   121.    87.5  140.5   84.5  161.5\n",
      "  65.5  113.5   87.   111.5  109.5   87.5  116.5  104.5  123.5   96.5\n",
      "  97.5  119.5   95.    44.   140.    73.5  105.5   15.5   71.5  108.\n",
      "  99.5   62.    65.    79.5   87.5  142.    93.5   50.   150.5  124.5\n",
      "  72.    84.5  112.5   56.5  180.   194.5  107.    94.5   76.5   64.5\n",
      " 107.    76.5   90.5  112.5  107.5  136.5   87.5   70.5  111.   134.5\n",
      "  84.   140.5   60.   124.    76.5   74.    59.    96.    66.25 164.\n",
      " 114.5   85.    83.    78.75 163.5  120.   153.    61.   113.5  112.5\n",
      "  77.5   98.   121.   100.5   85.5   61.5  105.   180.    74.5  120.\n",
      " 137.   120.    98.5   66.5   65.5  105.5  108.    63.    67.    93.\n",
      "  80.    73.5  121.   111.5   71.5  104.5   70.5  139.5  103.5  139.5\n",
      " 115.5   80.   205.   147.5   71.   138.5  103.    79.    78.75  54.\n",
      "  95.   110.5  124.   107.    70.5   70.   109.5   87.    66.5   60.\n",
      "  90.    82.    92.5   81.   100.   137.    73.5   85.   147.    62.5\n",
      " 104.5  110.    85.    65.5   85.5  113.    84.5  128.   120.5   51.5\n",
      " 124.5   70.5   87.5  169.    98.5   47.5  151.5  121.   132.5   80.\n",
      "  81.    96.   225.    84.    66.5   33.75  88.   153.   100.    51.\n",
      " 109.    72.5   53.5   63.5   99.   145.5   99.    68.5  164.5   87.5\n",
      " 109.   194.5  162.5  162.   129.5  133.   107.    52.5  143.5   92.\n",
      " 167.5  148.   101.5  102.    68.5  128.5  129.5   62.5   85.   167.5\n",
      " 110.5  125.   107.   154.5  105.5  154.5   52.5  133.    66.25  63.5\n",
      " 124.    76.5   53.75 115.   157.   174.   130.    84.   168.   164.5\n",
      "  39.5  205.    54.   112.5  140.    84.5   53.5  147.    61.5   96.\n",
      " 109.   153.5   81.    92.    72.   130.   111.5  106.5   95.    81.\n",
      " 140.   124.    47.    59.   132.5  119.   120.    49.   142.    85.\n",
      "  52.5   84.   110.   167.5   90.   177.   100.    51.5  161.5   61.5\n",
      "  73.   102.    69.5   91.5  107.5  107.    68.75  49.   107.    70.5\n",
      " 149.5   47.    98.    93.5  133.   117.5  100.   101.    64.5  114.\n",
      " 114.5   66.   110.5   77.   128.5  143.5  107.5   44.5   68.5  179.5\n",
      "  83.    91.5  237.5 ] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-9.320378393199235\n",
      "0.7082848399716379\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_random = rf_random.best_estimator_\n",
    "\n",
    "best_random_mae = np.mean(cross_val_score(best_random, X_train,y_train, y_train, scoring='neg_mean_absolute_error', cv=kf))\n",
    "r2_improvedBest= np.mean(cross_val_score(best_random, X_train,y_train, y_train, cv=kf))\n",
    "\n",
    "\n",
    "print(best_random_mae)\n",
    "print(r2_improvedBest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i think we should keep these functions\n",
    "#def choose_k(X_train, y_train, X_test):\n",
    "   # for i in range (1,166):\n",
    "    #    fs = SelectKBest(score_func=f_regression, k=i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "111\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-15.028165850149053\n",
      "0.6314194682370332\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-14.853583145328072\n",
      "0.6163164448853508\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae with outliers: -16.072153429386933\n",
      "mae without outliers: -18.259712800242152\n",
      "mae norm: -15.587554906082824\n",
      "mae stand: -15.704682185646654\n",
      "mae robust: -15.247617887846316\n",
      "r2 with outliers: 0.37699637410652365\n",
      "r2 without outliers: 0.1718976579460477\n",
      "r2 norm: 0.42025078382161934\n",
      "r2 stand: 0.37225133279746103\n",
      "r2 robust: 0.36144015404888136\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor as DTR\n",
    "\n",
    "tree_reg = DTR()\n",
    "tree_reg2 = DTR()\n",
    "tree_reg3 = DTR()\n",
    "tree_reg4 = DTR()\n",
    "tree_reg5 = DTR()\n",
    "\n",
    "tree_reg.fit(X_train,y_train)\n",
    "tree_reg2.fit(X2_train,y2_train)\n",
    "tree_reg3.fit(X_train_norm, y_train)\n",
    "tree_reg4.fit(X_train_stand, y_train)\n",
    "tree_reg5.fit(X_train_robust, y_train)\n",
    "\n",
    "\n",
    "\n",
    "tree1 = np.mean(cross_val_score(tree_reg, X_train, y_train, scoring='neg_mean_absolute_error', cv=3))\n",
    "\n",
    "tree2 = np.mean(cross_val_score(tree_reg2, X2_train, y2_train, scoring='neg_mean_absolute_error', cv=3))\n",
    "\n",
    "tree3 = np.mean(cross_val_score(tree_reg3, X_train_norm, y_train, scoring='neg_mean_absolute_error', cv=3))\n",
    "\n",
    "tree4 = np.mean(cross_val_score(tree_reg4, X_train_stand, y_train, scoring='neg_mean_absolute_error', cv=3))\n",
    "\n",
    "tree5 = np.mean(cross_val_score(tree_reg5, X_train_robust, y_train, scoring='neg_mean_absolute_error', cv=3))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tree1_r2 = np.mean(cross_val_score(tree_reg, X_train, y_train, cv=3))\n",
    "\n",
    "tree2_r2 = np.mean(cross_val_score(tree_reg2, X2_train, y2_train, cv=3))\n",
    "\n",
    "tree3_r2 = np.mean(cross_val_score(tree_reg3, X_train_norm, y_train, cv=3))\n",
    "\n",
    "tree4_r2 = np.mean(cross_val_score(tree_reg4, X_train_stand, y_train, cv=3))\n",
    "\n",
    "tree5_r2 = np.mean(cross_val_score(tree_reg5, X_train_robust, y_train, cv=3))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"mae with outliers: {tree1}\")\n",
    "\n",
    "print(f\"mae without outliers: {tree2}\")\n",
    "\n",
    "print(f\"mae norm: {tree3}\")\n",
    "\n",
    "print(f\"mae stand: {tree4}\")\n",
    "\n",
    "print(f\"mae robust: {tree5}\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"r2 with outliers: {tree1_r2}\")\n",
    "\n",
    "print(f\"r2 without outliers: {tree2_r2}\")\n",
    "\n",
    "print(f\"r2 norm: {tree3_r2}\")\n",
    "\n",
    "print(f\"r2 stand: {tree4_r2}\")\n",
    "\n",
    "print(f\"r2 robust: {tree5_r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's notice something: our decision tree and random forest seem to be very neck and neck with their score,\n",
    "\n",
    "both are clearly better than linear regression and lasso.\n",
    "\n",
    "it seems like the normalization is actually helping slightyl, especially in decision tree.\n",
    "our best model so far appears to be either decision tree with a robust or standarized scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = DTR()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_dt = GridSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_modeld = DTR(n_estimators = 10, random_state = 42)\n",
    "base_modeld.fit(X_train, y_train)\n",
    "\n",
    "base_modeld_mae = np.mean(cross_val_score(base_model, X_train, y_train, scoring='neg_mean_absolute_error', cv=kf))\n",
    "r2_improvedBd= np.mean(cross_val_score(base_model, X_train, y_train, cv=kf))\n",
    "\n",
    "\n",
    "print(base_model_mae)\n",
    "print(r2_improvedB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random = rf_random.best_estimator_\n",
    "random_accuracy = evaluate(best_random, X_train, y_train)\n",
    "\n",
    "best_random_mae = np.mean(cross_val_score(best_random, X_train, y_train, scoring='neg_mean_absolute_error', cv=kf))\n",
    "r2_improvedBest= np.mean(cross_val_score(best_random, X_train, y_train, cv=kf))\n",
    "\n",
    "\n",
    "print(best_random_mae)\n",
    "print(r2_improvedBest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
